{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RQ1JnfUBK-Z8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owsu2Qz_K-aA"
      },
      "source": [
        "### Question 0\n",
        "Load the telco data file we used in the previous labs. As we did there, we first read the telco file into a dataframe. Then we create the target, y, from the Churn column, and the features, X, are all the columns except for Churn. We then perform a train-test split. Now create a scaled version of the data, using Standard Scaler. Call the scaled version X_train_scaled, and X_test_scaled.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPsCkiWrLPAp",
        "outputId": "dfe78056-541d-42a6-b96d-6ee0faaf2d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_scaled shape: {(4922, 29)}\n",
            "X_test_scaled shape: {(2110, 29)}\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv(\"telco.csv\")\n",
        "\n",
        "y = df[\"Churn\"] \n",
        "x = df.drop(columns=[\"Churn\"])  \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "print(\"X_train_scaled shape:\", {x_train_scaled.shape})\n",
        "print(\"X_test_scaled shape:\", {x_test_scaled.shape})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8SoARQLK-aD"
      },
      "source": [
        "<h2>Question 1</h2>\n",
        "Build two versions of a default random forest model, using the normal data (X_train, X_test) and the scaled data (X_train_scaled, X_test_scaled). Print train and test scores for normal and scaled. </i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QquzqwGnK-aD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest on Normal Data:\n",
            "Train Score: {0.997765136123527}\n",
            "Test Score: {0.7829383886255924}\n",
            "\n",
            "Random Forest on Scaled Data:\n",
            "Train Score: {0.997765136123527}\n",
            "Test Score: {0.7819905213270142}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rf_normal = RandomForestClassifier()\n",
        "rf_normal.fit(x_train, y_train)\n",
        "\n",
        "rf_scaled = RandomForestClassifier()\n",
        "rf_scaled.fit(x_train_scaled, y_train)\n",
        "\n",
        "train_score_normal = rf_normal.score(x_train, y_train)\n",
        "test_score_normal = rf_normal.score(x_test, y_test)\n",
        "train_score_scaled = rf_scaled.score(x_train_scaled, y_train)\n",
        "test_score_scaled = rf_scaled.score(x_test_scaled, y_test)\n",
        "\n",
        "print(\"Random Forest on Normal Data:\")\n",
        "print(\"Train Score:\", {train_score_normal})\n",
        "print(\"Test Score:\", {test_score_normal})\n",
        "\n",
        "print(\"\\nRandom Forest on Scaled Data:\")\n",
        "print(\"Train Score:\", {train_score_scaled})\n",
        "print(\"Test Score:\", {test_score_scaled})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2CD7YRmK-aE"
      },
      "source": [
        "<h2>Question 2</h2>\n",
        "Build two versions of a default mlp model, using the normal data (X_train, X_test) and the scaled data (X_train_scaled, X_test_scaled). Print train and test scores for normal and scaled. </i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JDBnnYq4K-aE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP on Normal Data:\n",
            "Train Score: 0.7928\n",
            "Test Score: 0.7768\n",
            "\n",
            "MLP on Scaled Data:\n",
            "Train Score: 0.8885\n",
            "Test Score: 0.7559\n"
          ]
        }
      ],
      "source": [
        "mlp_normal = MLPClassifier(max_iter=500)\n",
        "mlp_normal.fit(x_train, y_train)\n",
        "\n",
        "mlp_scaled = MLPClassifier(max_iter=500)\n",
        "mlp_scaled.fit(x_train_scaled, y_train)\n",
        "\n",
        "\n",
        "train_score_normal = mlp_normal.score(x_train, y_train)\n",
        "test_score_normal = mlp_normal.score(x_test, y_test)\n",
        "train_score_scaled = mlp_scaled.score(x_train_scaled, y_train)\n",
        "test_score_scaled = mlp_scaled.score(x_test_scaled, y_test)\n",
        "\n",
        "print(\"MLP on Normal Data:\")\n",
        "print(f\"Train Score: {train_score_normal:.4f}\")\n",
        "print(f\"Test Score: {test_score_normal:.4f}\")\n",
        "\n",
        "print(\"\\nMLP on Scaled Data:\")\n",
        "print(f\"Train Score: {train_score_scaled:.4f}\")\n",
        "print(f\"Test Score: {test_score_scaled:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83O2c4mgfLro"
      },
      "source": [
        "<h2>Question 2a</h2>\n",
        "How much does scaling matter for the random forest model and mlp model you just tested? Why do you think that is?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "so Multi layer perceptron uses backpropagation with gradient descent which is gradient based and so Scaling has a large impact. while random forest is based on decision trees which should no matter the scale of the features find the same split point thus making scaling less relevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWJxDGGiK-aE"
      },
      "source": [
        "<h2>Question 3</h2>\n",
        "Now try mlp models with different values for the hidden layer size. Try with  two hidden layers, with sizes ranging from 1 to 20, incremented by 5. For each iteration, fit the model to the scaled data. Save the train and test scores for both in two lists. Also print the scaled and normal results at each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP with hidden layer sizes: (1, 1)\n",
            "scaled Train Score: 0.8064\n",
            "scaled Test Score: 0.7962\n",
            "Train Score: 0.8037\n",
            "Test Score: 0.7929\n",
            "\n",
            "Training MLP with hidden layer sizes: (6, 6)\n",
            "scaled Train Score: 0.8176\n",
            "scaled Test Score: 0.7919\n",
            "Train Score: 0.7972\n",
            "Test Score: 0.7853\n",
            "\n",
            "Training MLP with hidden layer sizes: (11, 11)\n",
            "scaled Train Score: 0.8304\n",
            "scaled Test Score: 0.7768\n",
            "Train Score: 0.8009\n",
            "Test Score: 0.7924\n",
            "\n",
            "Training MLP with hidden layer sizes: (16, 16)\n",
            "scaled Train Score: 0.8448\n",
            "scaled Test Score: 0.7588\n",
            "Train Score: 0.7948\n",
            "Test Score: 0.7787\n",
            "\n",
            "Final Results:\n",
            "Hidden Layer Size 1-1 -> scaled Train: 0.8064, scaled Test: 0.7962\n",
            "Hidden Layer Size 1-1 -> Train: 0.8037, Test: 0.7929\n",
            "Hidden Layer Size 6-6 -> scaled Train: 0.8176, scaled Test: 0.7919\n",
            "Hidden Layer Size 6-6 -> Train: 0.7972, Test: 0.7853\n",
            "Hidden Layer Size 11-11 -> scaled Train: 0.8304, scaled Test: 0.7768\n",
            "Hidden Layer Size 11-11 -> Train: 0.8009, Test: 0.7924\n",
            "Hidden Layer Size 16-16 -> scaled Train: 0.8448, scaled Test: 0.7588\n",
            "Hidden Layer Size 16-16 -> Train: 0.7948, Test: 0.7787\n"
          ]
        }
      ],
      "source": [
        "strain_scores = []\n",
        "stest_scores = []\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "\n",
        "for size in range(1, 21, 5):  \n",
        "    hidden_layer_sizes = (size, size)  \n",
        "    print(f\"\\nTraining MLP with hidden layer sizes: {hidden_layer_sizes}\")\n",
        "\n",
        "    # Using random state to make results consistent since we are making two lists\n",
        "    smlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, random_state=42, max_iter=500)\n",
        "    smlp.fit(x_train_scaled, y_train)\n",
        "\n",
        "    \n",
        "    strain_score = smlp.score(x_train_scaled, y_train)\n",
        "    stest_score = smlp.score(x_test_scaled, y_test)\n",
        "\n",
        "  \n",
        "    strain_scores.append(strain_score)\n",
        "    stest_scores.append(stest_score)\n",
        "\n",
        "   \n",
        "    print(f\"scaled Train Score: {strain_score:.4f}\")\n",
        "    print(f\"scaled Test Score: {stest_score:.4f}\")\n",
        "\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, random_state=42, max_iter=500)\n",
        "    mlp.fit(x_train, y_train)\n",
        "\n",
        " \n",
        "    train_score = mlp.score(x_train, y_train)\n",
        "    test_score = mlp.score(x_test, y_test)\n",
        "\n",
        "\n",
        "    train_scores.append(train_score)\n",
        "    test_scores.append(test_score)\n",
        "\n",
        "\n",
        "    print(f\"Train Score: {train_score:.4f}\")\n",
        "    print(f\"Test Score: {test_score:.4f}\")\n",
        "\n",
        "# Final Results Summary\n",
        "print(\"\\nFinal Results:\")\n",
        "for i, size in enumerate(range(1, 21, 5)):\n",
        "    print(f\"Hidden Layer Size {size}-{size} -> scaled Train: {strain_scores[i]:.4f}, scaled Test: {stest_scores[i]:.4f}\")\n",
        "    print(f\"Hidden Layer Size {size}-{size} -> Train: {train_scores[i]:.4f}, Test: {test_scores[i]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3BNvZsSK-aF"
      },
      "source": [
        "<h2>Question 4</h2>\n",
        "Read the HomesSoldHellerup.csv file, using read_csv (note that the separator is a semicolon and not a comma, which is the default). Use the columns 'Type', 'm2', 'Build Year', and 'Type of Sale' (assign this to X)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "afzAKaN8K-aF"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"HomesSoldHellerup.csv\", sep=\";\")\n",
        "\n",
        "y = df[\"Price\"] \n",
        "x = df[[\"Type\", \"m2\", \"Build Year\", \"Type of Sale\"]] \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAmjpOGNK-aG"
      },
      "source": [
        "<h2>Question 5</h2>\n",
        "Use get_dummies to produce dummy values for the non-numeric columns in X. (Use the optional parameter, columns, with a list of the columns that should get dummy values.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8tNgqkVbK-aG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   m2  Build Year  Type_Erhverv  Type_Lejlighed  Type_Rækkehus  Type_Stuehus  \\\n",
            "0  54        1932         False            True          False         False   \n",
            "1  87        1932         False            True          False         False   \n",
            "2  63        1932         False            True          False         False   \n",
            "3  54        1932         False            True          False         False   \n",
            "4  63        1932         False            True          False         False   \n",
            "\n",
            "   Type_Villa  Type of Sale_Andet  Type of Sale_Auktion  \\\n",
            "0       False               False                 False   \n",
            "1       False               False                 False   \n",
            "2       False               False                 False   \n",
            "3       False               False                 False   \n",
            "4       False               False                 False   \n",
            "\n",
            "   Type of Sale_Fam. Salg  \n",
            "0                   False  \n",
            "1                   False  \n",
            "2                   False  \n",
            "3                   False  \n",
            "4                   False  \n"
          ]
        }
      ],
      "source": [
        "X_dummies = pd.get_dummies(x, columns=[\"Type\", \"Type of Sale\"], drop_first=True)  # drop_first=True to avoid multicollinearity which will mes with our data\n",
        "\n",
        "print(X_dummies.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SimbMLkK-aG"
      },
      "source": [
        "<h2>Question 6</h2>\n",
        "How many columns were added by get_dummies?\n",
        "(Hint: Compare the number of columns from the initial data frame and the new data frame including the dummy variables.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DVDPgVy8K-aG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original columns: 4\n",
            "New columns after get_dummies: 10\n",
            "Number of columns added: 6\n"
          ]
        }
      ],
      "source": [
        "original_cols = x.shape[1]  # Number of original columns\n",
        "new_cols = X_dummies.shape[1]  # Number of columns after get_dummies\n",
        "added_cols = new_cols - original_cols  # Number of added columns\n",
        "\n",
        "print(f\"Original columns: {original_cols}\")\n",
        "print(f\"New columns after get_dummies: {new_cols}\")\n",
        "print(f\"Number of columns added: {added_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH2xqO7_K-aH"
      },
      "source": [
        "<h2>Question 7</h2>\n",
        "Create a Linear Regression model for two versions of the data -- the first with only numeric columns, m2 and Build Year. Then use the version with dummy values for Type and Type of Sale. Define the column price as the target, y. Conduct two train test splits, for the two versions of the data. One for the version with dummy variables, and one only including the columns m2 and Build Year.\n",
        "\n",
        "Print the score for train and test for each version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Version 1: Only numeric columns (m2, Build Year)\n",
        "X_numeric = df[[\"m2\", \"Build Year\"]]\n",
        "\n",
        "# Version 2: Numeric columns + Dummy Variables\n",
        "X_dummies = pd.get_dummies(df[[\"Type\", \"m2\", \"Build Year\", \"Type of Sale\"]], columns=[\"Type\", \"Type of Sale\"], drop_first=True)\n",
        "\n",
        "# Train-test split for both versions\n",
        "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numeric, y, test_size=0.3, random_state=42)\n",
        "X_train_dum, X_test_dum, y_train, y_test = train_test_split(X_dummies, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4fWs3zS0K-aH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression with Only Numeric Features:\n",
            "Train Score: 0.3095\n",
            "Test Score: 0.3665\n",
            "\n",
            "Linear Regression with Dummy Variables:\n",
            "Train Score: 0.3420\n",
            "Test Score: 0.3901\n"
          ]
        }
      ],
      "source": [
        "lr_numeric = LinearRegression()\n",
        "lr_numeric.fit(X_train_num, y_train)\n",
        "\n",
        "lr_dummies = LinearRegression()\n",
        "lr_dummies.fit(X_train_dum, y_train)\n",
        "\n",
        "# Get scores\n",
        "train_score_num = lr_numeric.score(X_train_num, y_train)\n",
        "test_score_num = lr_numeric.score(X_test_num, y_test)\n",
        "\n",
        "train_score_dum = lr_dummies.score(X_train_dum, y_train)\n",
        "test_score_dum = lr_dummies.score(X_test_dum, y_test)\n",
        "\n",
        "# Print results\n",
        "print(\"Linear Regression with Only Numeric Features:\")\n",
        "print(f\"Train Score: {train_score_num:.4f}\")\n",
        "print(f\"Test Score: {test_score_num:.4f}\")\n",
        "\n",
        "print(\"\\nLinear Regression with Dummy Variables:\")\n",
        "print(f\"Train Score: {train_score_dum:.4f}\")\n",
        "print(f\"Test Score: {test_score_dum:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_krGH96K-aH"
      },
      "source": [
        "<h2>Question 8</h2>\n",
        "Create a Decision Tree model for the same two versions of the data that you used in the previous question. Print the score for train and test for each version."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It was unclear which kind of decision tree so i made both. i hope this explains the duplication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "u6t8MkiDK-aI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree regressor with Only Numeric Features:\n",
            "Train Score: 0.9837\n",
            "Test Score: 0.2382\n",
            "\n",
            "Decision Tree regressor with Dummy Variables:\n",
            "Train Score: 0.9928\n",
            "Test Score: 0.3546\n",
            "\n",
            "Decision Tree classifier with Only Numeric Features:\n",
            "Train Score: 0.9837\n",
            "Test Score: 0.2382\n",
            "\n",
            "Decision Tree classifier  with Dummy Variables:\n",
            "Train Score: 0.9928\n",
            "Test Score: 0.3546\n"
          ]
        }
      ],
      "source": [
        "dt_numeric = DecisionTreeRegressor(random_state=42)\n",
        "dt_numeric.fit(X_train_num, y_train)\n",
        "\n",
        "dt_dummies = DecisionTreeRegressor(random_state=42)\n",
        "dt_dummies.fit(X_train_dum, y_train)\n",
        "\n",
        "dtc_numeric = DecisionTreeClassifier(random_state=42)\n",
        "dtc_numeric.fit(X_train_num, y_train)\n",
        "\n",
        "dtc_dummies = DecisionTreeClassifier(random_state=42)\n",
        "dtc_dummies.fit(X_train_dum, y_train)\n",
        "\n",
        "# Get scores\n",
        "train_score_num = dt_numeric.score(X_train_num, y_train)\n",
        "test_score_num = dt_numeric.score(X_test_num, y_test)\n",
        "\n",
        "train_score_dum = dt_dummies.score(X_train_dum, y_train)\n",
        "test_score_dum = dt_dummies.score(X_test_dum, y_test)\n",
        "\n",
        "train_score_numc = dtc_numeric.score(X_train_num, y_train)\n",
        "test_score_numc = dtc_numeric.score(X_test_num, y_test)\n",
        "\n",
        "train_score_dumc = dtc_dummies.score(X_train_dum, y_train)\n",
        "test_score_dumc = dtc_dummies.score(X_test_dum, y_test)\n",
        "\n",
        "# Print results\n",
        "print(\"Decision Tree regressor with Only Numeric Features:\")\n",
        "print(f\"Train Score: {train_score_num:.4f}\")\n",
        "print(f\"Test Score: {test_score_num:.4f}\")\n",
        "\n",
        "print(\"\\nDecision Tree regressor with Dummy Variables:\")\n",
        "print(f\"Train Score: {train_score_dum:.4f}\")\n",
        "print(f\"Test Score: {test_score_dum:.4f}\")\n",
        "\n",
        "print(\"\\nDecision Tree classifier with Only Numeric Features:\")\n",
        "print(f\"Train Score: {train_score_num:.4f}\")\n",
        "print(f\"Test Score: {test_score_num:.4f}\")\n",
        "\n",
        "print(\"\\nDecision Tree classifier  with Dummy Variables:\")\n",
        "print(f\"Train Score: {train_score_dum:.4f}\")\n",
        "print(f\"Test Score: {test_score_dum:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3RtgFxtK-aI"
      },
      "source": [
        "<h2>Question 9</h2>\n",
        "Now add dummy values for Road Name to the data. Create a train test split with the new version of the data. Create a Decision Tree model for this version of the data. Print the score for train and test for each version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEkP818RK-aI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Decision Tree with Dummy Variables (Including Road Name):\n",
            "Train Score: 0.9940\n",
            "Test Score: 0.6117\n",
            "\n",
            "Decision Tree with Dummy Variables (Including Road Name):\n",
            "Train Score: 0.7772\n",
            "Test Score: 0.0139\n"
          ]
        }
      ],
      "source": [
        "Xnew_dummies = pd.get_dummies(df[[\"Type\", \"m2\", \"Build Year\", \"Type of Sale\", \"Road name\"]], columns=[\"Type\", \"Type of Sale\", \"Road name\"], drop_first=True)\n",
        "X_train_dum, X_test_dum, y_train, y_test = train_test_split(Xnew_dummies, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt_dummies = DecisionTreeRegressor(random_state=42)\n",
        "dt_dummies.fit(X_train_dum, y_train)\n",
        "\n",
        "dtc_dummies = DecisionTreeClassifier(random_state=42)\n",
        "dtc_dummies.fit(X_train_dum, y_train)\n",
        "\n",
        "# Get scores for the Decision Tree model\n",
        "train_score_dum = dt_dummies.score(X_train_dum, y_train)\n",
        "test_score_dum = dt_dummies.score(X_test_dum, y_test)\n",
        "\n",
        "train_score_dumc = dtc_dummies.score(X_train_dum, y_train)\n",
        "test_score_dumc = dtc_dummies.score(X_test_dum, y_test)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nDecision Tree classifier with Dummy Variables (Including Road Name):\")\n",
        "print(f\"Train Score: {train_score_dum:.4f}\")\n",
        "print(f\"Test Score: {test_score_dum:.4f}\")\n",
        "\n",
        "print(\"\\nDecision Tree classifier with Dummy Variables (Including Road Name):\")\n",
        "print(f\"Train Score: {train_score_dumc:.4f}\")\n",
        "print(f\"Test Score: {test_score_dumc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t35uSRU0K-aI"
      },
      "source": [
        "<h2> Question 10</h2>\n",
        "Build a Random Forest regressor for this data. Set random_state, with otherwise default settings, and print train and test scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "x_tNKYvzK-aJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest Regressor with Dummy Variables (Including Road Name):\n",
            "Train Score: 0.9575\n",
            "Test Score: 0.7187\n"
          ]
        }
      ],
      "source": [
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "rf_regressor.fit(X_train_dum, y_train)\n",
        "\n",
        "# Get scores for Random Forest model\n",
        "train_score_rf = rf_regressor.score(X_train_dum, y_train)\n",
        "test_score_rf = rf_regressor.score(X_test_dum, y_test)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nRandom Forest Regressor with Dummy Variables (Including Road Name):\")\n",
        "print(f\"Train Score: {train_score_rf:.4f}\")\n",
        "print(f\"Test Score: {test_score_rf:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UChxIHMWfrQR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VenSGFEefp14"
      },
      "source": [
        "<h2>Question 10a</h2>\n",
        "\n",
        "Based on your results, which categorical features are most informative about price with this dataset?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jvtDbL-Af5_i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Feature  Importance\n",
            "0                             m2    0.412616\n",
            "1                     Build Year    0.231126\n",
            "77       Road name_Hellerupvej      0.163009\n",
            "69      Road name_Hambros Alle      0.034034\n",
            "9         Type of Sale_Fam. Salg    0.013424\n",
            "7             Type of Sale_Andet    0.012241\n",
            "154       Road name_Sundvænget      0.010591\n",
            "135  Road name_Richelieus Alle      0.009165\n",
            "106       Road name_Lemchesvej      0.006434\n",
            "156    Road name_Svanemøllevej      0.006288\n"
          ]
        }
      ],
      "source": [
        "feature_importance = rf_regressor.feature_importances_\n",
        "\n",
        "features = Xnew_dummies.columns\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': feature_importance\n",
        "})\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "print(feature_importance_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "it appears that type of sale and road name are the most informative in this dataset"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
