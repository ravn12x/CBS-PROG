{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MdoBqIECllb"
      },
      "source": [
        "# Text Data -- Movie Reviews and Sentiment\n",
        "\n",
        "In this lab we use movie reviews and build sentiment classifiers using a bag of words model. There are 25,000 training examples and 25,000 test examples in the original data set. To speed things up we have created a file just 5000 examples. If you have time you might try larger samples of the data, to see if accuracy improves. Also, in using countvectorizer we specified minimum and maximum document frequencies. These also improve speed, but often at the cost of accuracy, so you could also experiment with removing them to improve things.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "hide_input": false,
        "id": "XUEUUR0kClle"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdjltxjtCllg"
      },
      "source": [
        "Read the file imdb5000.csv, which you can get from Canvas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kdDagrBaCllg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"imdb5000.csv\")\n",
        "text = df['text']\n",
        "labels = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU2w2-K1Cllg",
        "outputId": "0b208e41-8da8-46c9-8084-86700458b1b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    b\"Zero Day leads you to think, even re-think w...\n",
              "1    b'Words can\\'t describe how bad this movie is....\n",
              "2    b'Everyone plays their part pretty well in thi...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPZfSwFgEE-f"
      },
      "source": [
        "Split the data into train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rH9H0gr7Cllh"
      },
      "outputs": [],
      "source": [
        "text_train, text_test,y_train, y_test = train_test_split(df['text'], df['sentiment'], random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ca5YAsQClli"
      },
      "source": [
        "### Question 0\n",
        "\n",
        "Use CountVectorizer to transform the text_data, by completing the following code. Assign the transformed data to X_data. Note that we use <b>min_df</b> of 10 and <b>max_df</b> of .5. These settings help keep things from getting too slow. You can experiment with different values -- higher minimums and lower maximums can speed things up, potentially with a reduction in accuracy.\n",
        "<p>\n",
        "Please take a moment to check the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html> scikit-learn documentation for CountVectorizer</a>. There you can see the different parameters and options, including min_df, max_df, ngram_range, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5up66viClli"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name '____' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m vect \u001b[38;5;241m=\u001b[39m CountVectorizer(min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m)\n\u001b[0;32m      3\u001b[0m vect \u001b[38;5;241m=\u001b[39m vect\u001b[38;5;241m.\u001b[39mfit(text_train )\n\u001b[1;32m----> 4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m vect\u001b[38;5;241m.\u001b[39mtransform(\u001b[43m____\u001b[49m)\n\u001b[0;32m      5\u001b[0m X_test \u001b[38;5;241m=\u001b[39m  vect\u001b[38;5;241m.\u001b[39mtransform(____)\n",
            "\u001b[1;31mNameError\u001b[0m: name '____' is not defined"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "vect = CountVectorizer(min_df=10, max_df=.5)\n",
        "\n",
        "vect = vect.fit(text_train )\n",
        "X_train = vect.transform(____)\n",
        "X_test =  vect.transform(____)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnEdwDJAZR5O"
      },
      "source": [
        "#### Question 0a\n",
        "\n",
        "Can you see how CountVectorizer is doing tokenizing? Can you give any examples of words or tokens that it ignores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXcFAw0lTIAS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxd_rNXKCllj"
      },
      "source": [
        "### Question 1\n",
        "Fit a LogisticRegression to X_train and y_train. Use the optional parameter C=.1, and max_iter=2000.\n",
        "Print the training and test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4Fw7zmeCllj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCH3uptFCllj"
      },
      "source": [
        "### Question 2\n",
        "Make a MultinomialNB classifier for X_train and y_train. Print training and test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2dVukGDCllj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZEZIH8nCllj"
      },
      "source": [
        "### Question 3\n",
        "Try changing CountVectorizer so that it constructs unigrams, bigrams and trigrams. You do this by setting the parameter ngram_range = (1,3), and creating a new vectorizer, as you did in Question 0 above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_kTJa8dCllj"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fdYI2oSURR"
      },
      "source": [
        "### Question 4\n",
        "Now use the new CountVectorizer to transform text_train and text_test, and report new train and test results for the two models you built above.\n",
        "(It might be convenient to use the function <b>applyModel</b>, defined below.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CkLYbeXSO9r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwfTSZogCllj"
      },
      "outputs": [],
      "source": [
        "def applyModel(model,name,X_train, y_train, X_test, y_test):\n",
        "    m = model.fit(X_train,y_train)\n",
        "    print(\"{} Training score: {:.3f}\".format(name, m.score(X_train, y_train)))\n",
        "    print(\"{} Test score: {:.3f}\".format(name, m.score(X_test, y_test)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pRXt7xxCllj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsIfT-dSCllj"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "For the above logistic regression model, sort the features by their coefficients, and print the top 10 features and their coefficients. Also print the 10 features with the lowest coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAk6bo7EU2l1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoOLSr2hZyYv"
      },
      "source": [
        "#### Question 5a\n",
        "\n",
        "Consider the top 10 positive features. Are there any of them which you would not consider a positive word? Why do you think they are on the list?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edZ-FXB6U3dm"
      },
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
