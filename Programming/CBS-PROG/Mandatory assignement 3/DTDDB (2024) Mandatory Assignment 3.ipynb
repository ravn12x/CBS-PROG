{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea8b424",
   "metadata": {},
   "source": [
    "## Digital Technologies and Data-Driven Business\n",
    "# Mandatory Assignment 3\n",
    "\n",
    "In the following, you find tasks that need to be solved as part of the third mandatory assignment in Digital Technologies and Data-driven Business. Once you solved the tasks, please save the .ipynb file (i.e., _File_ >> _Download as_ >> _Notebook (.ipynb)_) and upload the saved file to Canvas. The deadline is __November 4 at 10:00__. Mandatory assignments are either __approved__ or __not approved__. If a mandatory assignment is not approved, you will have the opportunity for a retake. \n",
    "\n",
    "Please read the instructions carefully and pay particular attention to the following points:\n",
    "1. Please provide correct Python code (i.e., code that can be executed without errors).\n",
    "2. Explain the code you have written in your own words (either with markdown or comments).\n",
    "3. You may work in groups but your submission must be individual, i.e. you each have to provide a functioning .ipynb file with __your own__ solutions and explanations. Do not copy the answers from others. Answers that are not your own (plagiarized) will lead to the mandatory assignment not being approved.\n",
    "\n",
    "Good luck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f0e86",
   "metadata": {},
   "source": [
    "### Copenhagen Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae91b00",
   "metadata": {},
   "source": [
    "Despite your great insights, RideDenmark has not been able to establish itself in the Danish market and closed down business. However, your skills are now well known in Copenhagen and a nearby bank has requested your services as part of their customer insights team. They have had a lot of customers leaving recently and they want to understand why customers are leaving so they can address the issue in advance.\n",
    "\n",
    "Emma, who is your new supervisor has extracted some data from the system regarding customer records. She sent it as a file named `bank-customers.csv` and left some questions that you can find below.\n",
    "\n",
    "__Emma:__ _We had a lot of customers leaving us recently. We would like to explore what attributes of customers contribute to this churn. Can you please help us with that?_\n",
    "\n",
    "__Important:__ Through the assignment you will be manipulating the dataframe in order to prepare it for machine learning. When you start a new task, you should always continue with the updated dataframe (do not import the data again after Task 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ac3f9",
   "metadata": {},
   "source": [
    "## Installing and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59055a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f9e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# This command helps you to show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98be1f9",
   "metadata": {},
   "source": [
    "# Task 1 (1 point)\n",
    "\n",
    "Read the file named `bank-customers.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c64028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f41ff0",
   "metadata": {},
   "source": [
    "# Task 2 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3dda73",
   "metadata": {},
   "source": [
    "__Emma:__ _The dataset contains a list of customer records. The column `Churn` indicates if the customer has left the bank. Please make a simple plot showing the distribution of this column._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe15cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df15fb6",
   "metadata": {},
   "source": [
    "__Emma:__ _Please also determine the distribution in absolute numbers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96179d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85c4e0",
   "metadata": {},
   "source": [
    "# Task 3 (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ecdc9",
   "metadata": {},
   "source": [
    "__Emma:__ _The columns `CustomerID` and `Surname` might not give us relevant information in predicting our target. Please drop these columns._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef554e",
   "metadata": {},
   "source": [
    "# Task 4 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826dad",
   "metadata": {},
   "source": [
    "__Emma:__ _Could you please indicate the statistical correlations between the numerical columns in a heatmap?_\n",
    "\n",
    "_Hint:_ Seaborn has a built-in `heatmap()` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48957c",
   "metadata": {},
   "source": [
    "__Emma:__ _Which attribute seems to have the highest positive and which the highest negative correlation with our target variable (`Churn`)?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666cce6",
   "metadata": {},
   "source": [
    "__Write your answer here:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e2da8",
   "metadata": {},
   "source": [
    "# Task 5 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9ed18",
   "metadata": {},
   "source": [
    "__Emma:__ _In order to use all of the remaining columns, we need to convert the categorical columns to numerical columns. Therefore, each card type has been assigned a score. Could you please edit the column `Card Type` so that the strings are replaced with the following numbers?_\n",
    "\n",
    "DIAMOND: 5<br>\n",
    "PLATINUM: 3.5<br>\n",
    "GOLD: 2.5<br>\n",
    "SILVER: 1\n",
    "\n",
    "_Hint:_ Look at the pandas `map` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee93b2",
   "metadata": {},
   "source": [
    "# Task 6 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884b3c0",
   "metadata": {},
   "source": [
    "__Emma:__ _We still have two categorical columns that we need to alter using a process called one-hot encoding. Please encode `Geography` and `Gender` using one-hot encoding._\n",
    "\n",
    "_Hint:_ Why do we need [one-hot encoding](https://towardsdatascience.com/encoding-categorical-variables-one-hot-vs-dummy-encoding-6d5b9c46e2db) and what is it?\n",
    "\n",
    "_Hint2:_ Take a look at the pandas documentation about [one-hot encoding](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8532452",
   "metadata": {},
   "source": [
    "# Task 7 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca290a64",
   "metadata": {},
   "source": [
    "__Emma:__ _My colleague told me that a crucial concept when working with most machine learning algorithms is to split your data into train and test data._\n",
    "\n",
    "_He also showed me that the following code splits your existing DataFrame into a test set and a train set. In this case, 80% of the data will be hosted in the train set, the remaining 20% will be hosted in the test set._\n",
    "\n",
    "_However, I still do not quite understand why one would want to split the dataset into two parts (train and test). Could you maybe give me some usefull insights?_\n",
    "\n",
    "Hint: Please describe in your own words. The lecture and readings provide useful information. Your answer should be min. 80 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e94e8-6816-43cf-b031-cf0155f602de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code provided by Emma's colleague\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa6328",
   "metadata": {},
   "source": [
    "__Write your answer here__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf584571",
   "metadata": {},
   "source": [
    "# Task 8 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55681e0",
   "metadata": {},
   "source": [
    "__Emma:__ _Thank you for the explanation. Now we need to get started with the machine learning. Could you please help split the data into a training and test dataset?_\n",
    "\n",
    "_Hint:_ The easiest way to split our data is using the built-in function `train_test_split` in Sci-Kit Learn. Before you make the actual split you should create the following variables, so the train_test_split knows what your target is and which attributes you want to use in the prediction:<br>\n",
    "\n",
    "__X__ - Should contain all the columns except the target.<br>\n",
    "__y__ - Should only contain the target column.\n",
    "\n",
    "The test size should be __30%__.\n",
    "\n",
    "You should end up having four variables that are named X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46368bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d64542",
   "metadata": {},
   "source": [
    "# Task 9 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a7579",
   "metadata": {},
   "source": [
    "__Emma:__ _Let's try to create our first model using the DecisionTreeClassifier from Sci-Kit Learn. One of our colleagues has provided us with the following code._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3).fit(X_train, y_train)\n",
    "\n",
    "y_pred = DTC.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {DTC.score(X_test, y_test)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05dc7c",
   "metadata": {},
   "source": [
    "__Emma:__ _Could you please help interpret the results for me? What does the accuracy, precision, and recall mean. And was our first model a success. Why/why not?_\n",
    "\n",
    "Write a minimum of 80 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6f284",
   "metadata": {},
   "source": [
    "__Write your answer here__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800454eb-524b-45e7-935a-b5ee834d91d2",
   "metadata": {},
   "source": [
    "# Task 10 (2 points)\n",
    "\n",
    "__Emma:__ _The code below allows us to plot the decision tree for our model. Please explain what you see. Explain how to read the contents of the nodes (i.e., boxes)._\n",
    "\n",
    "Write a minimum of 50 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c19ef-4825-4d4e-9207-a7e5111546a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "class_names = ['Not Churn', 'Churn']\n",
    "plot_tree(DTC, max_depth=3, fontsize=8, feature_names=X.columns.tolist(), filled=True, class_names=class_names)\n",
    "plt.title(\"Decision tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7c27d-03b7-4291-89ce-5a81cc101573",
   "metadata": {},
   "source": [
    "__Write your answer here__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4e1a2",
   "metadata": {},
   "source": [
    "# Task 11 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27b971",
   "metadata": {},
   "source": [
    "__Emma:__ _In order to better understand the results we should maybe create a confusion matrix to visualize our data. I have found the following code, but I am having trouble reading the visualization. Can you please help me? What does the different numbers mean?_\n",
    "\n",
    "Write a minimum of 40 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d435fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ax = sns.heatmap(conf_matrix, annot=True, fmt='d', cbar=False, cmap='Blues')\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a1269",
   "metadata": {},
   "source": [
    "__Write your answer here__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47d8f6",
   "metadata": {},
   "source": [
    "# Task 12 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4400a93",
   "metadata": {},
   "source": [
    "__Emma:__ _In order to obtain some insights from our model I have gotten one of our colleagues to write a code that creates a dataframe that contains the feature importance according to the DecisionTreeClassifier from before. Could you please visualize this in a sorted barchart?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(X_train.columns.to_list(), DTC.feature_importances_))\n",
    "feature_importance = pd.DataFrame(data, columns=['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e1349",
   "metadata": {},
   "source": [
    "# Task 13 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf7561",
   "metadata": {},
   "source": [
    "__Emma:__ _Now let's try to see if we can make our model even better. We should try tuning the `max_depth` hyperparameter of the DecisionTreeClassifier. Create a for loop that stores the accuracy, precision, and recall of models with a `max_depth` of 3, 5, 10, 15, 20. I have created a result dataframe that you can use to store the data of the different iterations._\n",
    "\n",
    "_Hint:_ You can reuse much of the code from previous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ddddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['max_depth', 'Accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ace35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58ee59",
   "metadata": {},
   "source": [
    "__Emma:__ _Which `max_depth` gave the highest accuracy? Explain in your own words what the hypterparameter `max_depth` does._\n",
    "\n",
    "Hint: You could look into the documentation (**https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa66b3f",
   "metadata": {},
   "source": [
    "__Write your answer here__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed17b12",
   "metadata": {},
   "source": [
    "# Task 14 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1ba17",
   "metadata": {},
   "source": [
    "__Emma:__ _Great work - we got a couple of models to run and extracted a lot of data about the performance. How was your overall impression - did we succeed in making a useful model? Are there any insights I can bring to the executive team. Did we gather some new information based on our machine learning that we did not obtain from our standard statistical correlation?_\n",
    "\n",
    "_Hint_: Change the `max_depth` hyperparameter in Task 9 to the optimal value from Task 13. Afterwards, run Task 9 to Task 12 again. Write a minimum of 100 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7416b7",
   "metadata": {},
   "source": [
    "__Write your answer here__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
